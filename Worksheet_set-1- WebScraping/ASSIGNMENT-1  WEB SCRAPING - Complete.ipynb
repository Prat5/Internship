{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66264bd9",
   "metadata": {},
   "source": [
    "## 1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3dfa5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b127cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Header Tags\n",
       "0  From today's featured article\n",
       "1               Did you know ...\n",
       "2                    In the news\n",
       "3                    On this day\n",
       "4       Today's featured picture\n",
       "5       Other areas of Wikipedia\n",
       "6    Wikipedia's sister projects\n",
       "7            Wikipedia languages"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)\n",
    "header_tags = []\n",
    "for main_file in soup.find_all('h2',class_= \"mp-h2\"):\n",
    "    header_tags.append(main_file.text)\n",
    "df = pd.DataFrame(header_tags,columns = ['Header Tags'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf07d8",
   "metadata": {},
   "source": [
    "## 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01131a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL1 = 'https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc'\n",
    "URL2 = 'https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt'\n",
    "page1 = requests.get(URL1)\n",
    "page2 = requests.get(URL2)\n",
    "page1\n",
    "page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa13860",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page1.content)\n",
    "soup2 = BeautifulSoup(page2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d100f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Movie_Name Rating  Year\n",
       "0                        The Shawshank Redemption    9.3  1994\n",
       "1                                   The Godfather    9.2  1972\n",
       "2                                 The Dark Knight    9.1  2008\n",
       "3   The Lord of the Rings: The Return of the King    9.0  2003\n",
       "4                                Schindler's List    9.0  1993\n",
       "..                                            ...    ...   ...\n",
       "95                             North by Northwest    8.3  1959\n",
       "96                                        Vertigo    8.3  1958\n",
       "97                            Singin' in the Rain    8.3  1952\n",
       "98                                   Citizen Kane    8.3  1941\n",
       "99              M - Eine Stadt sucht einen Mörder    8.3  1931\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f = []\n",
    "for main_file in soup.find_all('div',class_=\"lister-item-content\"):\n",
    "    heading = main_file.h3.a.text\n",
    "    rating = main_file.find('div',class_=\"inline-block ratings-imdb-rating\").text.strip('\\n')\n",
    "    release_year = main_file.h3.find(\"span\",class_=\"lister-item-year text-muted unbold\").text.strip('()')\n",
    "    df = (heading,rating,release_year)\n",
    "    df_f.append(df)\n",
    "for main_file in soup2.find_all('div',class_=\"lister-item-content\"):\n",
    "    heading = main_file.h3.a.text\n",
    "    rating = main_file.find('div',class_=\"inline-block ratings-imdb-rating\").text.strip('\\n')\n",
    "    release_year = main_file.h3.find(\"span\",class_=\"lister-item-year text-muted unbold\").text.strip('()')\n",
    "    df = (heading,rating,release_year)\n",
    "    df_f.append(df)\n",
    "df_final = pd.DataFrame(df_f,columns=['Movie_Name','Rating','Year'])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a3efa",
   "metadata": {},
   "source": [
    "## 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a192cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Golmaal</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nayakan</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Sholay</td>\n",
       "      <td>1975</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>K.G.F: Chapter 1</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Angoor</td>\n",
       "      <td>1982</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Virumandi</td>\n",
       "      <td>2004</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Maheshinte Prathikaaram</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                           Name  Year Rating\n",
       "0     1                       Jai Bhim  2021    8.4\n",
       "1     2                     Anbe Sivam  2003    8.4\n",
       "2     3              Pariyerum Perumal  2018    8.4\n",
       "3     4                        Golmaal  1979    8.4\n",
       "4     5                        Nayakan  1987    8.4\n",
       "..  ...                            ...   ...    ...\n",
       "95   96                         Sholay  1975    8.0\n",
       "96   97               K.G.F: Chapter 1  2018    8.0\n",
       "97   98                         Angoor  1982    8.0\n",
       "98   99                      Virumandi  2004    8.0\n",
       "99  100        Maheshinte Prathikaaram  2016    8.0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "page = requests.get(URL).text\n",
    "soup = BeautifulSoup(page,'lxml')\n",
    "\n",
    "df_1 = []\n",
    "for td in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    Rank = td.text.strip().split('\\n')[0].strip('.')\n",
    "    Name = td.text.strip().split('\\n')[1]\n",
    "    Year = td.text.strip().split('\\n')[2].strip('()')\n",
    "    df_1.append([Rank,Name,Year])\n",
    "df_2 = []\n",
    "for td in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    Rating = td.text.strip()\n",
    "    df_2.append([Rating])\n",
    "df1 = pd.DataFrame(df_1,columns=['Rank','Name','Year'])\n",
    "df2 = pd.DataFrame(df_2,columns=['Rating'])\n",
    "df1['Rating'] = df2\n",
    "df1\n",
    "imdb_top100_Indian_Movies = df1.iloc[:100,:]\n",
    "imdb_top100_Indian_Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29187d",
   "metadata": {},
   "source": [
    "## 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bags\u0002ladies/pl/p7vbp . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43022617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the number of pages you want the data for :10\n",
      "['https://meesho.com/bags-ladies/pl/p7vbp?page=1', 'https://meesho.com/bags-ladies/pl/p7vbp?page=2', 'https://meesho.com/bags-ladies/pl/p7vbp?page=3', 'https://meesho.com/bags-ladies/pl/p7vbp?page=4', 'https://meesho.com/bags-ladies/pl/p7vbp?page=5', 'https://meesho.com/bags-ladies/pl/p7vbp?page=6', 'https://meesho.com/bags-ladies/pl/p7vbp?page=7', 'https://meesho.com/bags-ladies/pl/p7vbp?page=8', 'https://meesho.com/bags-ladies/pl/p7vbp?page=9', 'https://meesho.com/bags-ladies/pl/p7vbp?page=10']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voguish Alluring Women Handbags</td>\n",
       "      <td>584</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gorgeous Stylish Women Handbags</td>\n",
       "      <td>351</td>\n",
       "      <td>22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ravishing Versatile Women Handbags</td>\n",
       "      <td>484</td>\n",
       "      <td>17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elite Alluring Women Handbags</td>\n",
       "      <td>281</td>\n",
       "      <td>26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ravishing Fancy Women Handbags</td>\n",
       "      <td>469</td>\n",
       "      <td>18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Handbags</td>\n",
       "      <td>685</td>\n",
       "      <td>13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Gorgeous Alluring Women Handbags</td>\n",
       "      <td>663</td>\n",
       "      <td>13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Elegant Fashionable Women Handbags</td>\n",
       "      <td>684</td>\n",
       "      <td>13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Graceful Versatile Women Handbags</td>\n",
       "      <td>210</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Graceful Versatile Women Handbags</td>\n",
       "      <td>384</td>\n",
       "      <td>21%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Product Name Price Discounts\n",
       "0       Voguish Alluring Women Handbags   584       15%\n",
       "1       Gorgeous Stylish Women Handbags   351       22%\n",
       "2    Ravishing Versatile Women Handbags   484       17%\n",
       "3         Elite Alluring Women Handbags   281       26%\n",
       "4        Ravishing Fancy Women Handbags   469       18%\n",
       "..                                  ...   ...       ...\n",
       "155                           Handbags    685       13%\n",
       "156    Gorgeous Alluring Women Handbags   663       13%\n",
       "157  Elegant Fashionable Women Handbags   684       13%\n",
       "158   Graceful Versatile Women Handbags   210       30%\n",
       "159   Graceful Versatile Women Handbags   384       21%\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_pages = int(input('Please enter the number of pages you want the data for :'))+1\n",
    "\n",
    "URL = []\n",
    "for i in range(1,no_pages):\n",
    "    url = ('https://meesho.com/bags-ladies/pl/p7vbp?page={}'.format(i))\n",
    "    URL.append(url)\n",
    "print(URL)\n",
    "\n",
    "meesho = []\n",
    "for i in URL:\n",
    "    page = requests.get(i)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    for main_file in soup.find_all('div',class_='sc-dkzDqf ProductList__GridCol-sc-8lnc8o-0 kEYUOG ZnDzz'):\n",
    "        title = main_file.a.p.text\n",
    "        price = main_file.a.h5.text.replace('₹','')\n",
    "        discount = main_file.find('div',class_=\"Card__BaseCard-sc-b3n78k-0 fVRkfg NewProductCard__PriceRow-sc-j0e7tu-5 dYYUrF NewProductCard__PriceRow-sc-j0e7tu-5 dYYUrF\").span.text.split(' ')[0]\n",
    "        meesho.append([title,price,discount])\n",
    "meesho_final = pd.DataFrame(meesho,columns=['Product Name','Price','Discounts'])\n",
    "#meesho_final.to_excel('Meesho.xlsx')\n",
    "meesho_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59b2815",
   "metadata": {},
   "source": [
    "## 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316ac15",
   "metadata": {},
   "source": [
    "### a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc4ab5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b5103_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Position</th>        <th class=\"col_heading level0 col1\" >Team</th>        <th class=\"col_heading level0 col2\" >Matches</th>        <th class=\"col_heading level0 col3\" >Points</th>        <th class=\"col_heading level0 col4\" >Rating</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_b5103_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_b5103_row0_col1\" class=\"data row0 col1\" >New Zealand</td>\n",
       "                        <td id=\"T_b5103_row0_col2\" class=\"data row0 col2\" >17</td>\n",
       "                        <td id=\"T_b5103_row0_col3\" class=\"data row0 col3\" >2,054</td>\n",
       "                        <td id=\"T_b5103_row0_col4\" class=\"data row0 col4\" >121</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "                        <td id=\"T_b5103_row1_col1\" class=\"data row1 col1\" >England</td>\n",
       "                        <td id=\"T_b5103_row1_col2\" class=\"data row1 col2\" >32</td>\n",
       "                        <td id=\"T_b5103_row1_col3\" class=\"data row1 col3\" >3,793</td>\n",
       "                        <td id=\"T_b5103_row1_col4\" class=\"data row1 col4\" >119</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "                        <td id=\"T_b5103_row2_col1\" class=\"data row2 col1\" >Australia</td>\n",
       "                        <td id=\"T_b5103_row2_col2\" class=\"data row2 col2\" >28</td>\n",
       "                        <td id=\"T_b5103_row2_col3\" class=\"data row2 col3\" >3,244</td>\n",
       "                        <td id=\"T_b5103_row2_col4\" class=\"data row2 col4\" >116</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "                        <td id=\"T_b5103_row3_col1\" class=\"data row3 col1\" >India</td>\n",
       "                        <td id=\"T_b5103_row3_col2\" class=\"data row3 col2\" >38</td>\n",
       "                        <td id=\"T_b5103_row3_col3\" class=\"data row3 col3\" >4,162</td>\n",
       "                        <td id=\"T_b5103_row3_col4\" class=\"data row3 col4\" >110</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "                        <td id=\"T_b5103_row4_col1\" class=\"data row4 col1\" >South Africa</td>\n",
       "                        <td id=\"T_b5103_row4_col2\" class=\"data row4 col2\" >31</td>\n",
       "                        <td id=\"T_b5103_row4_col3\" class=\"data row4 col3\" >3,167</td>\n",
       "                        <td id=\"T_b5103_row4_col4\" class=\"data row4 col4\" >102</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "                        <td id=\"T_b5103_row5_col1\" class=\"data row5 col1\" >Pakistan</td>\n",
       "                        <td id=\"T_b5103_row5_col2\" class=\"data row5 col2\" >27</td>\n",
       "                        <td id=\"T_b5103_row5_col3\" class=\"data row5 col3\" >2,524</td>\n",
       "                        <td id=\"T_b5103_row5_col4\" class=\"data row5 col4\" >93</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "                        <td id=\"T_b5103_row6_col1\" class=\"data row6 col1\" >Bangladesh</td>\n",
       "                        <td id=\"T_b5103_row6_col2\" class=\"data row6 col2\" >36</td>\n",
       "                        <td id=\"T_b5103_row6_col3\" class=\"data row6 col3\" >3,350</td>\n",
       "                        <td id=\"T_b5103_row6_col4\" class=\"data row6 col4\" >93</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "                        <td id=\"T_b5103_row7_col1\" class=\"data row7 col1\" >Sri Lanka</td>\n",
       "                        <td id=\"T_b5103_row7_col2\" class=\"data row7 col2\" >35</td>\n",
       "                        <td id=\"T_b5103_row7_col3\" class=\"data row7 col3\" >2,835</td>\n",
       "                        <td id=\"T_b5103_row7_col4\" class=\"data row7 col4\" >81</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "                        <td id=\"T_b5103_row8_col1\" class=\"data row8 col1\" >West Indies</td>\n",
       "                        <td id=\"T_b5103_row8_col2\" class=\"data row8 col2\" >36</td>\n",
       "                        <td id=\"T_b5103_row8_col3\" class=\"data row8 col3\" >2,788</td>\n",
       "                        <td id=\"T_b5103_row8_col4\" class=\"data row8 col4\" >77</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b5103_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "                        <td id=\"T_b5103_row9_col1\" class=\"data row9 col1\" >Afghanistan</td>\n",
       "                        <td id=\"T_b5103_row9_col2\" class=\"data row9 col2\" >23</td>\n",
       "                        <td id=\"T_b5103_row9_col3\" class=\"data row9 col3\" >1,562</td>\n",
       "                        <td id=\"T_b5103_row9_col4\" class=\"data row9 col4\" >68</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16fd43b7910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "page = requests.get(url).text\n",
    "soup = BeautifulSoup(page,'lxml')\n",
    "\n",
    "data = []\n",
    "main_file1 = soup.find('tr',class_=\"rankings-block__banner\")\n",
    "position = main_file1.find('td',class_=\"rankings-block__banner--pos\").text\n",
    "team = main_file1.find('span',class_=\"u-hide-phablet\").text\n",
    "matches = main_file1.find('td',class_=\"rankings-block__banner--matches\").text\n",
    "points = main_file1.find('td',class_=\"rankings-block__banner--points\").text\n",
    "rating = main_file1.find('td',class_=\"rankings-block__banner--rating u-text-right\").text.strip()\n",
    "data.append([position,team,matches,points,rating])\n",
    "\n",
    "\n",
    "data1 = []\n",
    "counter = 1\n",
    "for main_file in soup.find_all('tr',class_=\"table-body\"):\n",
    "    if counter != 10:\n",
    "        position = main_file.td.text\n",
    "        team = main_file.find('span',class_=\"u-hide-phablet\").text\n",
    "        m = []\n",
    "        for x in main_file.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "            m.append(x.text)\n",
    "        matches = m[0]\n",
    "        points = m[1]\n",
    "        rating = main_file.find('td',class_=\"table-body__cell u-text-right rating\").text\n",
    "        data1.append([position,team,matches,points,rating])\n",
    "        counter+=1\n",
    "    else:\n",
    "        break\n",
    "final_df = data+data1\n",
    "Top_10_ODI_teams_men = pd.DataFrame(final_df,columns=['Position','Team','Matches','Points','Rating']).style.hide_index()\n",
    "Top_10_ODI_teams_men"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886a826",
   "metadata": {},
   "source": [
    "### b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8866fa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career Best Rating</th>\n",
       "      <th>Career Best Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>873</td>\n",
       "      <td>873 v England</td>\n",
       "      <td>13/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>811</td>\n",
       "      <td>911 v England</td>\n",
       "      <td>12/07/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>796</td>\n",
       "      <td>813 v Sri Lanka</td>\n",
       "      <td>10/03/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>791</td>\n",
       "      <td>885 v Sri Lanka</td>\n",
       "      <td>06/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "      <td>798 v England</td>\n",
       "      <td>25/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>776</td>\n",
       "      <td>776 v Bangladesh</td>\n",
       "      <td>20/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "      <td>796 v India</td>\n",
       "      <td>26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "      <td>880 v Pakistan</td>\n",
       "      <td>26/01/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>741</td>\n",
       "      <td>779 v England</td>\n",
       "      <td>08/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joe Root</td>\n",
       "      <td>ENG</td>\n",
       "      <td>740</td>\n",
       "      <td>824 v Sri Lanka</td>\n",
       "      <td>13/10/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team Rating Career Best Rating Career Best Date\n",
       "0             Babar Azam  PAK    873      873 v England       13/07/2021\n",
       "1            Virat Kohli  IND    811      911 v England       12/07/2018\n",
       "2        Quinton de Kock   SA    796    813 v Sri Lanka       10/03/2019\n",
       "3           Rohit Sharma  IND    791    885 v Sri Lanka       06/07/2019\n",
       "4            Aaron Finch  AUS    779      798 v England       25/06/2019\n",
       "5  Rassie van der Dussen   SA    776   776 v Bangladesh       20/03/2022\n",
       "6         Jonny Bairstow  ENG    775        796 v India       26/03/2021\n",
       "7           David Warner  AUS    762     880 v Pakistan       26/01/2017\n",
       "8           Fakhar Zaman  PAK    741      779 v England       08/07/2021\n",
       "9               Joe Root  ENG    740    824 v Sri Lanka       13/10/2018"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting').text\n",
    "soup = BeautifulSoup(page,'lxml')\n",
    "\n",
    "data1 = []\n",
    "main_file1 = soup.find('tr',class_=\"rankings-block__banner\")\n",
    "name = main_file1.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    "team = main_file1.find('div',class_=\"rankings-block__banner--nationality\").text.strip()\n",
    "points = main_file1.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "career_best = main_file1.find('span',class_=\"rankings-block__career-best-text\").text.strip().split(',')[0]\n",
    "career_best_date = main_file1.find('span',class_=\"rankings-block__career-best-text\").text.strip().split(',')[1]\n",
    "data1.append([name,team,points,career_best,career_best_date])\n",
    "\n",
    "\n",
    "data = []\n",
    "counter = 1\n",
    "for main_file in soup.find_all('tr',class_=\"table-body\"):\n",
    "    if counter != 10:\n",
    "        name = main_file.find('td',class_=\"table-body__cell rankings-table__name name\").a.text\n",
    "        team = main_file.find('span',class_=\"table-body__logo-text\").text\n",
    "        points = main_file.find('td',class_=\"table-body__cell rating\").text\n",
    "        career_best = main_file.find('td',class_=\"table-body__cell u-text-right u-hide-phablet\").text.strip().split(',')[0]\n",
    "        career_best_date = main_file.find('td',class_=\"table-body__cell u-text-right u-hide-phablet\").text.strip().split(',')[1]\n",
    "        data.append([name,team,points,career_best,career_best_date])\n",
    "        counter+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "final_df = data1+data\n",
    "Top_10_men_Batting_players=pd.DataFrame(final_df,columns=['Player','Team','Rating','Career Best Rating','Career Best Date'])\n",
    "Top_10_men_Batting_players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23872281",
   "metadata": {},
   "source": [
    "### c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21783325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career Best Rating</th>\n",
       "      <th>Career Best Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "      <td>770 v West Indies</td>\n",
       "      <td>22/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "      <td>733 v England</td>\n",
       "      <td>26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "      <td>711 v Sri Lanka</td>\n",
       "      <td>04/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "      <td>691 v Bangladesh</td>\n",
       "      <td>26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>681</td>\n",
       "      <td>712 v Ireland</td>\n",
       "      <td>24/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "      <td>841 v West Indies</td>\n",
       "      <td>01/11/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>664</td>\n",
       "      <td>725 v Sri Lanka</td>\n",
       "      <td>25/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>658</td>\n",
       "      <td>724 v England</td>\n",
       "      <td>29/05/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "      <td>783 v New Zealand</td>\n",
       "      <td>29/03/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "      <td>806 v Pakistan</td>\n",
       "      <td>21/09/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating Career Best Rating Career Best Date\n",
       "0       Trent Boult   NZ    737  770 v West Indies       22/06/2019\n",
       "1    Josh Hazlewood  AUS    709      733 v England       26/01/2018\n",
       "2      Chris Woakes  ENG    700    711 v Sri Lanka       04/07/2021\n",
       "3        Matt Henry   NZ    691   691 v Bangladesh       26/03/2021\n",
       "4  Mujeeb Ur Rahman  AFG    681      712 v Ireland       24/01/2021\n",
       "5    Jasprit Bumrah  IND    679  841 v West Indies       01/11/2018\n",
       "6      Mehedi Hasan  BAN    664    725 v Sri Lanka       25/05/2021\n",
       "7     Kagiso Rabada   SA    658      724 v England       29/05/2017\n",
       "8    Mitchell Starc  AUS    652  783 v New Zealand       29/03/2015\n",
       "9       Rashid Khan  AFG    650     806 v Pakistan       21/09/2018"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling').text\n",
    "soup = BeautifulSoup(page,'lxml')\n",
    "\n",
    "data1 = []\n",
    "main_file1 = soup.find('tr',class_=\"rankings-block__banner\")\n",
    "name = main_file1.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    "team = main_file1.find('div',class_=\"rankings-block__banner--nationality\").text.strip()\n",
    "points = main_file1.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "career_best = main_file1.find('span',class_=\"rankings-block__career-best-text\").text.strip().split(',')[0]\n",
    "career_best_date = main_file1.find('span',class_=\"rankings-block__career-best-text\").text.strip().split(',')[1]\n",
    "data1.append([name,team,points,career_best,career_best_date])\n",
    "\n",
    "\n",
    "data = []\n",
    "counter = 1\n",
    "for main_file in soup.find_all('tr',class_=\"table-body\"):\n",
    "    if counter != 10:\n",
    "        name = main_file.find('td',class_=\"table-body__cell rankings-table__name name\").a.text\n",
    "        team = main_file.find('span',class_=\"table-body__logo-text\").text\n",
    "        points = main_file.find('td',class_=\"table-body__cell rating\").text\n",
    "        career_best = main_file.find('td',class_=\"table-body__cell u-text-right u-hide-phablet\").text.strip().split(',')[0]\n",
    "        career_best_date = main_file.find('td',class_=\"table-body__cell u-text-right u-hide-phablet\").text.strip().split(',')[1]\n",
    "        data.append([name,team,points,career_best,career_best_date])\n",
    "        counter+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "final_df = data1+data\n",
    "Top_10_men_Bowling_players=pd.DataFrame(final_df,columns=['Player','Team','Rating','Career Best Rating','Career Best Date'])\n",
    "Top_10_men_Bowling_players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc176a7f",
   "metadata": {},
   "source": [
    "## 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f04770",
   "metadata": {},
   "source": [
    "### a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9efe54b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_028d3_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Position</th>        <th class=\"col_heading level0 col1\" >Team</th>        <th class=\"col_heading level0 col2\" >Matches</th>        <th class=\"col_heading level0 col3\" >Points</th>        <th class=\"col_heading level0 col4\" >Rating</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_028d3_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_028d3_row0_col1\" class=\"data row0 col1\" >Australia</td>\n",
       "                        <td id=\"T_028d3_row0_col2\" class=\"data row0 col2\" >20</td>\n",
       "                        <td id=\"T_028d3_row0_col3\" class=\"data row0 col3\" >3,263</td>\n",
       "                        <td id=\"T_028d3_row0_col4\" class=\"data row0 col4\" >163</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "                        <td id=\"T_028d3_row1_col1\" class=\"data row1 col1\" >South Africa</td>\n",
       "                        <td id=\"T_028d3_row1_col2\" class=\"data row1 col2\" >21</td>\n",
       "                        <td id=\"T_028d3_row1_col3\" class=\"data row1 col3\" >2,580</td>\n",
       "                        <td id=\"T_028d3_row1_col4\" class=\"data row1 col4\" >123</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "                        <td id=\"T_028d3_row2_col1\" class=\"data row2 col1\" >England</td>\n",
       "                        <td id=\"T_028d3_row2_col2\" class=\"data row2 col2\" >21</td>\n",
       "                        <td id=\"T_028d3_row2_col3\" class=\"data row2 col3\" >2,474</td>\n",
       "                        <td id=\"T_028d3_row2_col4\" class=\"data row2 col4\" >118</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "                        <td id=\"T_028d3_row3_col1\" class=\"data row3 col1\" >India</td>\n",
       "                        <td id=\"T_028d3_row3_col2\" class=\"data row3 col2\" >22</td>\n",
       "                        <td id=\"T_028d3_row3_col3\" class=\"data row3 col3\" >2,221</td>\n",
       "                        <td id=\"T_028d3_row3_col4\" class=\"data row3 col4\" >101</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "                        <td id=\"T_028d3_row4_col1\" class=\"data row4 col1\" >New Zealand</td>\n",
       "                        <td id=\"T_028d3_row4_col2\" class=\"data row4 col2\" >24</td>\n",
       "                        <td id=\"T_028d3_row4_col3\" class=\"data row4 col3\" >2,342</td>\n",
       "                        <td id=\"T_028d3_row4_col4\" class=\"data row4 col4\" >98</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "                        <td id=\"T_028d3_row5_col1\" class=\"data row5 col1\" >Bangladesh</td>\n",
       "                        <td id=\"T_028d3_row5_col2\" class=\"data row5 col2\" >5</td>\n",
       "                        <td id=\"T_028d3_row5_col3\" class=\"data row5 col3\" >475</td>\n",
       "                        <td id=\"T_028d3_row5_col4\" class=\"data row5 col4\" >95</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "                        <td id=\"T_028d3_row6_col1\" class=\"data row6 col1\" >West Indies</td>\n",
       "                        <td id=\"T_028d3_row6_col2\" class=\"data row6 col2\" >21</td>\n",
       "                        <td id=\"T_028d3_row6_col3\" class=\"data row6 col3\" >1,801</td>\n",
       "                        <td id=\"T_028d3_row6_col4\" class=\"data row6 col4\" >86</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "                        <td id=\"T_028d3_row7_col1\" class=\"data row7 col1\" >Pakistan</td>\n",
       "                        <td id=\"T_028d3_row7_col2\" class=\"data row7 col2\" >19</td>\n",
       "                        <td id=\"T_028d3_row7_col3\" class=\"data row7 col3\" >1,304</td>\n",
       "                        <td id=\"T_028d3_row7_col4\" class=\"data row7 col4\" >69</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "                        <td id=\"T_028d3_row8_col1\" class=\"data row8 col1\" >Ireland</td>\n",
       "                        <td id=\"T_028d3_row8_col2\" class=\"data row8 col2\" >5</td>\n",
       "                        <td id=\"T_028d3_row8_col3\" class=\"data row8 col3\" >240</td>\n",
       "                        <td id=\"T_028d3_row8_col4\" class=\"data row8 col4\" >48</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_028d3_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "                        <td id=\"T_028d3_row9_col1\" class=\"data row9 col1\" >Sri Lanka</td>\n",
       "                        <td id=\"T_028d3_row9_col2\" class=\"data row9 col2\" >5</td>\n",
       "                        <td id=\"T_028d3_row9_col3\" class=\"data row9 col3\" >233</td>\n",
       "                        <td id=\"T_028d3_row9_col4\" class=\"data row9 col4\" >47</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16fd4d9a220>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "page = requests.get(url).text\n",
    "soup = BeautifulSoup(page,'lxml')\n",
    "\n",
    "data = []\n",
    "main_file1 = soup.find('tr',class_=\"rankings-block__banner\")\n",
    "position = main_file1.find('td',class_=\"rankings-block__banner--pos\").text\n",
    "team = main_file1.find('span',class_=\"u-hide-phablet\").text\n",
    "matches = main_file1.find('td',class_=\"rankings-block__banner--matches\").text\n",
    "points = main_file1.find('td',class_=\"rankings-block__banner--points\").text\n",
    "rating = main_file1.find('td',class_=\"rankings-block__banner--rating u-text-right\").text.strip()\n",
    "data.append([position,team,matches,points,rating])\n",
    "\n",
    "\n",
    "data1 = []\n",
    "counter = 1\n",
    "for main_file in soup.find_all('tr',class_=\"table-body\"):\n",
    "    if counter != 10:\n",
    "        position = main_file.td.text\n",
    "        team = main_file.find('span',class_=\"u-hide-phablet\").text\n",
    "        m = []\n",
    "        for x in main_file.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "            m.append(x.text)\n",
    "        matches = m[0]\n",
    "        points = m[1]\n",
    "        rating = main_file.find('td',class_=\"table-body__cell u-text-right rating\").text\n",
    "        data1.append([position,team,matches,points,rating])\n",
    "        counter+=1\n",
    "    else:\n",
    "        break\n",
    "final_df = data+data1\n",
    "Top_10_ODI_teams_women = pd.DataFrame(final_df,columns=['Position','Team','Matches','Points','Rating']).style.hide_index()\n",
    "Top_10_ODI_teams_women"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08642daf",
   "metadata": {},
   "source": [
    "### b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c96c6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career Best</th>\n",
       "      <th>Career Best Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>730</td>\n",
       "      <td>776 v India</td>\n",
       "      <td>21/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "      <td>734 v England</td>\n",
       "      <td>03/02/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>720</td>\n",
       "      <td>725 v India</td>\n",
       "      <td>07/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>715</td>\n",
       "      <td>834 v New Zealand</td>\n",
       "      <td>24/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>712</td>\n",
       "      <td>713 v West Indies</td>\n",
       "      <td>15/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>705</td>\n",
       "      <td>712 v India</td>\n",
       "      <td>25/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>701</td>\n",
       "      <td>791 v India</td>\n",
       "      <td>27/06/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>696</td>\n",
       "      <td>756 v Australia</td>\n",
       "      <td>02/03/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>696</td>\n",
       "      <td>839 v Australia</td>\n",
       "      <td>24/12/2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>663</td>\n",
       "      <td>797 v England</td>\n",
       "      <td>28/02/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating        Career Best Career Best Date\n",
       "0       Alyssa Healy  AUS    730        776 v India       21/09/2021\n",
       "1        Beth Mooney  AUS    725      734 v England       03/02/2022\n",
       "2    Laura Wolvaardt   SA    720        725 v India       07/03/2021\n",
       "3        Meg Lanning  AUS    715  834 v New Zealand       24/02/2016\n",
       "4     Rachael Haynes  AUS    712  713 v West Indies       15/03/2022\n",
       "5     Natalie Sciver  ENG    705        712 v India       25/02/2019\n",
       "6     Tammy Beaumont  ENG    701        791 v India       27/06/2021\n",
       "7  Amy Satterthwaite   NZ    696    756 v Australia       02/03/2017\n",
       "8        Mithali Raj  IND    696    839 v Australia       24/12/2004\n",
       "9    Smriti Mandhana  IND    663      797 v England       28/02/2019"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting').text\n",
    "soup = BeautifulSoup(page,'lxml')\n",
    "\n",
    "data1 = []\n",
    "main_file1 = soup.find('tr',class_=\"rankings-block__banner\")\n",
    "name = main_file1.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    "team = main_file1.find('div',class_=\"rankings-block__banner--nationality\").text.strip()\n",
    "points = main_file1.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "career_best = main_file1.find('span',class_=\"rankings-block__career-best-text\").text.strip().split(',')[0]\n",
    "career_best_date = main_file1.find('span',class_=\"rankings-block__career-best-text\").text.strip().split(',')[1]\n",
    "data1.append([name,team,points,career_best,career_best_date])\n",
    "\n",
    "\n",
    "data = []\n",
    "counter = 1\n",
    "for main_file in soup.find_all('tr',class_=\"table-body\"):\n",
    "    if counter != 10:\n",
    "        name = main_file.find('td',class_=\"table-body__cell rankings-table__name name\").a.text\n",
    "        team = main_file.find('span',class_=\"table-body__logo-text\").text\n",
    "        points = main_file.find('td',class_=\"table-body__cell rating\").text\n",
    "        career_best = main_file.find('td',class_=\"table-body__cell u-text-right u-hide-phablet\").text.strip().split(',')[0]\n",
    "        career_best_date = main_file.find('td',class_=\"table-body__cell u-text-right u-hide-phablet\").text.strip().split(',')[1]\n",
    "        data.append([name,team,points,career_best,career_best_date])\n",
    "        counter+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "final_df = data1+data\n",
    "Top_10_women_Batting_players=pd.DataFrame(final_df,columns=['Player','Team','Rating','Career Best','Career Best Date'])\n",
    "Top_10_women_Batting_players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e427ea",
   "metadata": {},
   "source": [
    "### c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120bcb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Career Best Rating</th>\n",
       "      <th>Career Best Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>773</td>\n",
       "      <td>773 v New Zealand</td>\n",
       "      <td>20/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "      <td>808 v New Zealand</td>\n",
       "      <td>10/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>716</td>\n",
       "      <td>766 v West Indies</td>\n",
       "      <td>11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>713</td>\n",
       "      <td>743 v India</td>\n",
       "      <td>07/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>688</td>\n",
       "      <td>749 v West Indies</td>\n",
       "      <td>10/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>680</td>\n",
       "      <td>680 v New Zealand</td>\n",
       "      <td>17/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>674</td>\n",
       "      <td>796 v England</td>\n",
       "      <td>28/02/2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>648</td>\n",
       "      <td>719 v West Indies</td>\n",
       "      <td>05/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>643</td>\n",
       "      <td>644 v Bangladesh</td>\n",
       "      <td>18/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>623</td>\n",
       "      <td>623 v New Zealand</td>\n",
       "      <td>20/03/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating Career Best Rating Career Best Date\n",
       "0  Sophie Ecclestone  ENG    773  773 v New Zealand       20/03/2022\n",
       "1      Jess Jonassen  AUS    726  808 v New Zealand       10/04/2021\n",
       "2       Megan Schutt  AUS    716  766 v West Indies       11/09/2019\n",
       "3     Shabnim Ismail   SA    713        743 v India       07/03/2021\n",
       "4     Marizanne Kapp   SA    688  749 v West Indies       10/09/2021\n",
       "5     Ayabonga Khaka   SA    680  680 v New Zealand       17/03/2022\n",
       "6     Jhulan Goswami  IND    674      796 v England       28/02/2007\n",
       "7       Ellyse Perry  AUS    648  719 v West Indies       05/09/2019\n",
       "8    Hayley Matthews   WI    643   644 v Bangladesh       18/03/2022\n",
       "9         Kate Cross  ENG    623  623 v New Zealand       20/03/2022"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling').text\n",
    "soup = BeautifulSoup(page,'lxml')\n",
    "\n",
    "data1 = []\n",
    "main_file1 = soup.find('tr',class_=\"rankings-block__banner\")\n",
    "name = main_file1.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    "team = main_file1.find('div',class_=\"rankings-block__banner--nationality\").text.strip()\n",
    "points = main_file1.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "career_best = main_file1.find('span',class_=\"rankings-block__career-best-text\").text.strip().split(',')[0]\n",
    "career_best_date = main_file1.find('span',class_=\"rankings-block__career-best-text\").text.strip().split(',')[1]\n",
    "data1.append([name,team,points,career_best,career_best_date])\n",
    "\n",
    "\n",
    "data = []\n",
    "counter = 1\n",
    "for main_file in soup.find_all('tr',class_=\"table-body\"):\n",
    "    if counter != 10:\n",
    "        name = main_file.find('td',class_=\"table-body__cell rankings-table__name name\").a.text\n",
    "        team = main_file.find('span',class_=\"table-body__logo-text\").text\n",
    "        points = main_file.find('td',class_=\"table-body__cell rating\").text\n",
    "        career_best = main_file.find('td',class_=\"table-body__cell u-text-right u-hide-phablet\").text.strip().split(',')[0]\n",
    "        career_best_date = main_file.find('td',class_=\"table-body__cell u-text-right u-hide-phablet\").text.strip().split(',')[1]\n",
    "        data.append([name,team,points,career_best,career_best_date])\n",
    "        counter+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "final_df = data1+data\n",
    "Top_10_women_Bowling_players=pd.DataFrame(final_df,columns=['Player','Team','Rating','Career Best Rating','Career Best Date'])\n",
    "Top_10_women_Bowling_players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c9220",
   "metadata": {},
   "source": [
    "## 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4896a8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on : https://coreyms.com/page/1\n",
      "working on : https://coreyms.com/page/2\n",
      "working on : https://coreyms.com/page/3\n",
      "working on : https://coreyms.com/page/4\n",
      "working on : https://coreyms.com/page/5\n",
      "working on : https://coreyms.com/page/6\n",
      "working on : https://coreyms.com/page/7\n",
      "working on : https://coreyms.com/page/8\n",
      "working on : https://coreyms.com/page/9\n",
      "working on : https://coreyms.com/page/10\n",
      "working on : https://coreyms.com/page/11\n",
      "working on : https://coreyms.com/page/12\n",
      "working on : https://coreyms.com/page/13\n",
      "working on : https://coreyms.com/page/14\n",
      "working on : https://coreyms.com/page/15\n",
      "working on : https://coreyms.com/page/16\n",
      "working on : https://coreyms.com/page/17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>YouTube_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>In this video, we will be learning how to crea...</td>\n",
       "      <td>https://youtube.com/watch?v=z0gguhEmWiY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://youtube.com/watch?v=_P7X8tMplsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://youtube.com/watch?v=fKl2JW_qrso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://youtube.com/watch?v=IEEhzQoKtQU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>Hey everyone. I wanted to give you an update o...</td>\n",
       "      <td>YouTube_url : Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Quick Tip: Use a Wooden Pallet as a Lumber Rack</td>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>Making a lumber rack for the workshop is a tas...</td>\n",
       "      <td>YouTube_url : Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>How to Record Sound From Your Computer’s Speak...</td>\n",
       "      <td>2014-03-02</td>\n",
       "      <td>At times, you may want to record sound from yo...</td>\n",
       "      <td>YouTube_url : Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Ems and Rems for Sizing</td>\n",
       "      <td>2013-09-21</td>\n",
       "      <td>Ems and Rems both are scalable units in CSS wh...</td>\n",
       "      <td>YouTube_url : Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>How to Build a Pergola</td>\n",
       "      <td>2013-09-12</td>\n",
       "      <td></td>\n",
       "      <td>YouTube_url : Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Adding Custom Web Fonts to Your Web Site Using...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>Adding custom web fonts to your website is one...</td>\n",
       "      <td>https://youtube.com/watch?v=y2AlgMII1OU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Heading       Date  \\\n",
       "0    Python Tutorial: Zip Files – Creating and Extr... 2019-11-19   \n",
       "1    Python Data Science Tutorial: Analyzing the 20... 2019-10-17   \n",
       "2    Python Multiprocessing Tutorial: Run Code in P... 2019-09-21   \n",
       "3    Python Threading Tutorial: Run Code Concurrent... 2019-09-12   \n",
       "4                                  Update (2019-09-03) 2019-09-03   \n",
       "..                                                 ...        ...   \n",
       "157    Quick Tip: Use a Wooden Pallet as a Lumber Rack 2014-04-21   \n",
       "158  How to Record Sound From Your Computer’s Speak... 2014-03-02   \n",
       "159                            Ems and Rems for Sizing 2013-09-21   \n",
       "160                             How to Build a Pergola 2013-09-12   \n",
       "161  Adding Custom Web Fonts to Your Web Site Using... 2013-07-01   \n",
       "\n",
       "                                               Content  \\\n",
       "0    In this video, we will be learning how to crea...   \n",
       "1    In this Python Programming video, we will be l...   \n",
       "2    In this Python Programming video, we will be l...   \n",
       "3    In this Python Programming video, we will be l...   \n",
       "4    Hey everyone. I wanted to give you an update o...   \n",
       "..                                                 ...   \n",
       "157  Making a lumber rack for the workshop is a tas...   \n",
       "158  At times, you may want to record sound from yo...   \n",
       "159  Ems and Rems both are scalable units in CSS wh...   \n",
       "160                                                      \n",
       "161  Adding custom web fonts to your website is one...   \n",
       "\n",
       "                                 YouTube_url  \n",
       "0    https://youtube.com/watch?v=z0gguhEmWiY  \n",
       "1    https://youtube.com/watch?v=_P7X8tMplsw  \n",
       "2    https://youtube.com/watch?v=fKl2JW_qrso  \n",
       "3    https://youtube.com/watch?v=IEEhzQoKtQU  \n",
       "4                YouTube_url : Not Available  \n",
       "..                                       ...  \n",
       "157              YouTube_url : Not Available  \n",
       "158              YouTube_url : Not Available  \n",
       "159              YouTube_url : Not Available  \n",
       "160              YouTube_url : Not Available  \n",
       "161  https://youtube.com/watch?v=y2AlgMII1OU  \n",
       "\n",
       "[162 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = []\n",
    "for i in range(1,18):\n",
    "    url = 'https://coreyms.com/page/{}'.format(i)\n",
    "    URL.append(url)\n",
    "\n",
    "corey = []\n",
    "for i in URL:\n",
    "    print('working on :', i)\n",
    "    page = requests.get(i)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "    for main_file in soup.find_all('article'):\n",
    "        Heading = main_file.h2.a.text\n",
    "        Date = pd.to_datetime(main_file.find('time',class_=\"entry-time\").text)\n",
    "        Content = main_file.find('div',class_=\"entry-content\").p.text\n",
    "        try:\n",
    "            url = main_file.find('iframe',class_=\"youtube-player\")['src'].split('/')[4].split('?')[0]\n",
    "            YouTube_url = 'https://youtube.com/watch?v='+url\n",
    "        except:\n",
    "            YouTube_url = 'YouTube_url : Not Available'\n",
    "        corey.append([Heading,Date,Content,YouTube_url])\n",
    "Corey_MS = pd.DataFrame(corey,columns=['Heading','Date','Content','YouTube_url'])\n",
    "Corey_MS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0e006",
   "metadata": {},
   "source": [
    "## 8) Write a python program to scrape house details from mentioned URL. It should include house title, location,area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69ba2fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>Price</th>\n",
       "      <th>EMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 BHK Flat  For Sale  In Jains Prakruti, Jayan...</td>\n",
       "      <td>Kanakapura Road, Jayanagar, Bangalore, Karnata...</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "      <td>85,971/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Jayan...</td>\n",
       "      <td>Independent House, SBI Branch Jayanagar 9th bl...</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>₹2.7 Crores</td>\n",
       "      <td>1.55 Lacs/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 BHK Flat  For Sale  In Benaka Apartments In ...</td>\n",
       "      <td>871, 5th Cross Rd, Indira Nagar 1st Stage, Sta...</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>₹85 Lacs</td>\n",
       "      <td>48,717/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Prak...</td>\n",
       "      <td>Independent House, 6th C cross 3rd main rd nea...</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>₹1.35 Crores</td>\n",
       "      <td>77,374/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Brigade Gateway ...</td>\n",
       "      <td>Brigade Gateway  Dr Rajkumar Road, Rajaji Naga...</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>₹2.62 Crores</td>\n",
       "      <td>1.5 Lacs/Month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         House Title  \\\n",
       "0  2 BHK Flat  For Sale  In Jains Prakruti, Jayan...   \n",
       "1  4 BHK In Independent House  For Sale  In Jayan...   \n",
       "2  3 BHK Flat  For Sale  In Benaka Apartments In ...   \n",
       "3  4+ BHK In Independent House  For Sale  In Prak...   \n",
       "4  3 BHK Apartment  For Sale  In Brigade Gateway ...   \n",
       "\n",
       "                                            Location          Area  \\\n",
       "0  Kanakapura Road, Jayanagar, Bangalore, Karnata...     Jayanagar   \n",
       "1  Independent House, SBI Branch Jayanagar 9th bl...     Jayanagar   \n",
       "2  871, 5th Cross Rd, Indira Nagar 1st Stage, Sta...   Indiranagar   \n",
       "3  Independent House, 6th C cross 3rd main rd nea...  Rajaji Nagar   \n",
       "4  Brigade Gateway  Dr Rajkumar Road, Rajaji Naga...  Rajaji Nagar   \n",
       "\n",
       "          Price              EMI  \n",
       "0   ₹1.5 Crores     85,971/Month  \n",
       "1   ₹2.7 Crores  1.55 Lacs/Month  \n",
       "2      ₹85 Lacs     48,717/Month  \n",
       "3  ₹1.35 Crores     77,374/Month  \n",
       "4  ₹2.62 Crores   1.5 Lacs/Month  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIifSx7ImxhdCI6MTIuOTMwNzczNSwibG9uIjo3Ny41ODM4MzAyLCJwbGFjZUlkIjoiQ2hJSjJkZGxaNWdWcmpzUmgxQk9BYWYtb3JzIiwicGxhY2VOYW1lIjoiSmF5YW5hZ2FyIn0seyJsYXQiOjEyLjk3ODM2OTIsImxvbiI6NzcuNjQwODM1NiwicGxhY2VJZCI6IkNoSUprUU4zR0tRV3Jqc1JOaEJRSnJoR0Q3VSIsInBsYWNlTmFtZSI6IkluZGlyYW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Rajajinagar,&locality=Jayanagar,&locality=Indiranagar'\n",
    "page = requests.get(url,'lxml')\n",
    "soup = BeautifulSoup(page.content)\n",
    "df = []\n",
    "for main_file in soup.find_all('article'):\n",
    "    name = main_file.find('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\").text\n",
    "    location = main_file.find('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\").text\n",
    "\n",
    "    if 'Jayanagar' in name:\n",
    "        area = 'Jayanagar'\n",
    "    elif 'Rajaji Nagar' in name:\n",
    "        area = 'Rajaji Nagar'\n",
    "    else:\n",
    "        area = 'Indiranagar'\n",
    "    rent = main_file.find('div',class_=\"flex flex-col w-33pe items-center bo tp:w-half po:w-full border-r-0\").div.text\n",
    "    dep = []\n",
    "    for subfile in main_file.find_all('div',class_=\"font-semi-bold heading-6\"):\n",
    "        dep.append(subfile.text.strip('₹'))\n",
    "    emi = dep[1]\n",
    "    df.append([name,location,area,rent,emi])\n",
    "NoBroker = pd.DataFrame(df,columns=['House Title','Location','Area','Price','EMI'])\n",
    "NoBroker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4481c63",
   "metadata": {},
   "source": [
    "#### Using BeautifulSoup and Selenium for web scraping nobroker.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e714292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-92a955bbc370>:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of listings needed :10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>Price</th>\n",
       "      <th>EMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 BHK Flat  For Sale  In Jains Prakruti, Jayan...</td>\n",
       "      <td>Kanakapura Road, Jayanagar, Bangalore, Karnata...</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "      <td>85,971/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Jayan...</td>\n",
       "      <td>Independent House, SBI Branch Jayanagar 9th bl...</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>₹2.7 Crores</td>\n",
       "      <td>1.55 Lacs/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 BHK Flat  For Sale  In Benaka Apartments In ...</td>\n",
       "      <td>871, 5th Cross Rd, Indira Nagar 1st Stage, Sta...</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>₹85 Lacs</td>\n",
       "      <td>48,717/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Prak...</td>\n",
       "      <td>Independent House, 6th C cross 3rd main rd nea...</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>₹1.35 Crores</td>\n",
       "      <td>77,374/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Brigade Gateway ...</td>\n",
       "      <td>Brigade Gateway  Dr Rajkumar Road, Rajaji Naga...</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>₹2.62 Crores</td>\n",
       "      <td>1.5 Lacs/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2 BHK Flat  For Sale  In Jains Prakruti, Jayan...</td>\n",
       "      <td>Kanakapura Road, Jayanagar, Bangalore, Karnata...</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "      <td>85,971/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Jayan...</td>\n",
       "      <td>Independent House, SBI Branch Jayanagar 9th bl...</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>₹2.7 Crores</td>\n",
       "      <td>1.55 Lacs/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3 BHK Flat  For Sale  In Benaka Apartments In ...</td>\n",
       "      <td>871, 5th Cross Rd, Indira Nagar 1st Stage, Sta...</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>₹85 Lacs</td>\n",
       "      <td>48,717/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Prak...</td>\n",
       "      <td>Independent House, 6th C cross 3rd main rd nea...</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>₹1.35 Crores</td>\n",
       "      <td>77,374/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Brigade Gateway ...</td>\n",
       "      <td>Brigade Gateway  Dr Rajkumar Road, Rajaji Naga...</td>\n",
       "      <td>Rajaji Nagar</td>\n",
       "      <td>₹2.62 Crores</td>\n",
       "      <td>1.5 Lacs/Month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            House Title  \\\n",
       "0     2 BHK Flat  For Sale  In Jains Prakruti, Jayan...   \n",
       "1     4 BHK In Independent House  For Sale  In Jayan...   \n",
       "2     3 BHK Flat  For Sale  In Benaka Apartments In ...   \n",
       "3     4+ BHK In Independent House  For Sale  In Prak...   \n",
       "4     3 BHK Apartment  For Sale  In Brigade Gateway ...   \n",
       "...                                                 ...   \n",
       "9995  2 BHK Flat  For Sale  In Jains Prakruti, Jayan...   \n",
       "9996  4 BHK In Independent House  For Sale  In Jayan...   \n",
       "9997  3 BHK Flat  For Sale  In Benaka Apartments In ...   \n",
       "9998  4+ BHK In Independent House  For Sale  In Prak...   \n",
       "9999  3 BHK Apartment  For Sale  In Brigade Gateway ...   \n",
       "\n",
       "                                               Location          Area  \\\n",
       "0     Kanakapura Road, Jayanagar, Bangalore, Karnata...     Jayanagar   \n",
       "1     Independent House, SBI Branch Jayanagar 9th bl...     Jayanagar   \n",
       "2     871, 5th Cross Rd, Indira Nagar 1st Stage, Sta...   Indiranagar   \n",
       "3     Independent House, 6th C cross 3rd main rd nea...  Rajaji Nagar   \n",
       "4     Brigade Gateway  Dr Rajkumar Road, Rajaji Naga...  Rajaji Nagar   \n",
       "...                                                 ...           ...   \n",
       "9995  Kanakapura Road, Jayanagar, Bangalore, Karnata...     Jayanagar   \n",
       "9996  Independent House, SBI Branch Jayanagar 9th bl...     Jayanagar   \n",
       "9997  871, 5th Cross Rd, Indira Nagar 1st Stage, Sta...   Indiranagar   \n",
       "9998  Independent House, 6th C cross 3rd main rd nea...  Rajaji Nagar   \n",
       "9999  Brigade Gateway  Dr Rajkumar Road, Rajaji Naga...  Rajaji Nagar   \n",
       "\n",
       "             Price              EMI  \n",
       "0      ₹1.5 Crores     85,971/Month  \n",
       "1      ₹2.7 Crores  1.55 Lacs/Month  \n",
       "2         ₹85 Lacs     48,717/Month  \n",
       "3     ₹1.35 Crores     77,374/Month  \n",
       "4     ₹2.62 Crores   1.5 Lacs/Month  \n",
       "...            ...              ...  \n",
       "9995   ₹1.5 Crores     85,971/Month  \n",
       "9996   ₹2.7 Crores  1.55 Lacs/Month  \n",
       "9997      ₹85 Lacs     48,717/Month  \n",
       "9998  ₹1.35 Crores     77,374/Month  \n",
       "9999  ₹2.62 Crores   1.5 Lacs/Month  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "URL = \"https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIifSx7ImxhdCI6MTIuOTMwNzczNSwibG9uIjo3Ny41ODM4MzAyLCJwbGFjZUlkIjoiQ2hJSjJkZGxaNWdWcmpzUmgxQk9BYWYtb3JzIiwicGxhY2VOYW1lIjoiSmF5YW5hZ2FyIn0seyJsYXQiOjEyLjk3ODM2OTIsImxvbiI6NzcuNjQwODM1NiwicGxhY2VJZCI6IkNoSUprUU4zR0tRV3Jqc1JOaEJRSnJoR0Q3VSIsInBsYWNlTmFtZSI6IkluZGlyYW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Rajajinagar,&locality=Jayanagar,&locality=Indiranagar\"\n",
    "driver.get(URL)\n",
    "\n",
    "no_of_listing = int(input('Enter the number of listings needed :'))\n",
    "page = driver.page_source\n",
    "soup = BeautifulSoup(page)\n",
    "df = []\n",
    "count = 1\n",
    "while count<no_of_listing:\n",
    "    for main_file in soup.find_all('article'):\n",
    "        name = main_file.find('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\").text\n",
    "        location = main_file.find('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\").text\n",
    "\n",
    "        if 'Jayanagar' in name:\n",
    "            area = 'Jayanagar'\n",
    "        elif 'Rajaji Nagar' in name:\n",
    "            area = 'Rajaji Nagar'\n",
    "        else:\n",
    "            area = 'Indiranagar'\n",
    "        rent = main_file.find('div',class_=\"flex flex-col w-33pe items-center bo tp:w-half po:w-full border-r-0\").div.text\n",
    "        dep = []\n",
    "        for subfile in main_file.find_all('div',class_=\"font-semi-bold heading-6\"):\n",
    "            dep.append(subfile.text.strip('₹'))\n",
    "        emi = dep[1]\n",
    "        df.append([name,location,area,rent,emi])\n",
    "        count +=1\n",
    "NoBroker = pd.DataFrame(df,columns=['House Title','Location','Area','Price','EMI'])\n",
    "NoBroker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32408f5",
   "metadata": {},
   "source": [
    "## 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "    i) Restaurant name\n",
    "    ii) Cuisine\n",
    "    iii) Location\n",
    "    iv) Ratings\n",
    "    v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d71b7967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World Cafe</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B Que</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glasshouse</td>\n",
       "      <td>European</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Restaurant_Name       Cuisine  \\\n",
       "0                    Castle Barbeque  North Indian   \n",
       "1                    Jungle Jamboree  North Indian   \n",
       "2                    Castle Barbeque       Chinese   \n",
       "3                         Cafe Knosh       Italian   \n",
       "4               The Barbeque Company  North Indian   \n",
       "5                        India Grill  North Indian   \n",
       "6                     Delhi Barbeque  North Indian   \n",
       "7   The Monarch - Bar Be Que Village  North Indian   \n",
       "8                         World Cafe  North Indian   \n",
       "9                  Indian Grill Room  North Indian   \n",
       "10                   Mad 4 Bar B Que  North Indian   \n",
       "11                       Barbeque 29  North Indian   \n",
       "12                        Glasshouse      European   \n",
       "\n",
       "                                             Location Rating  \\\n",
       "0                      Connaught Place, Central Delhi    3.5   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi    3.9   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi    3.9   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...    4.3   \n",
       "4                  Gardens Galleria,Sector 38A, Noida      4   \n",
       "5                Hilton Garden Inn,Saket, South Delhi    3.9   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi    3.7   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad    3.8   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad    4.2   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon    4.3   \n",
       "10                               Sector 29, Faridabad    3.6   \n",
       "11                                     NIT, Faridabad    4.2   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...      4   \n",
       "\n",
       "                                            Image_url  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special','lxml')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)\n",
    "dineout = []\n",
    "for main_file in soup.find_all('div',class_=\"restnt-card restaurant\"):\n",
    "    Restaurant_Name = main_file.div.a.text\n",
    "    Cuisine = main_file.find('span',class_=\"double-line-ellipsis\").a.text\n",
    "    Location = main_file.find('div',class_=\"restnt-loc ellipsis\").text\n",
    "    Rating = main_file.find('div',class_=\"restnt-rating rating-4\").text\n",
    "    Image_url = main_file.find('img',class_=\"no-img\")['data-src']\n",
    "    dineout.append([Restaurant_Name,Cuisine,Location,Rating,Image_url])\n",
    "Dineout = pd.DataFrame(dineout,columns=['Restaurant_Name','Cuisine','Location','Rating','Image_url'])\n",
    "Dineout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ac10e",
   "metadata": {},
   "source": [
    "## 10) Write a python program to scrape first 10 product details which include product name , price , Image URL from https://www.bewakoof.com/women-clothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088438f",
   "metadata": {},
   "source": [
    "### Using BeautifulSoup and Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a2ebdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of listings needed : 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-60d3b049f8c1>:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Discounted Price</th>\n",
       "      <th>Actual Price</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marshmello Mask Round Neck 3/4th Sleeve T-Shirt</td>\n",
       "      <td>₹ 249</td>\n",
       "      <td>499</td>\n",
       "      <td>https://images.bewakoof.com/t320/meteor-grey-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women's Blue Escape The Ordinary Boyfriend T-s...</td>\n",
       "      <td>₹ 399</td>\n",
       "      <td>549</td>\n",
       "      <td>https://images.bewakoof.com/t320/nimbus-grey-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Ordinary Round Neck 3/4th Sleeve T-Shirt</td>\n",
       "      <td>₹ 249</td>\n",
       "      <td>799</td>\n",
       "      <td>https://images.bewakoof.com/t320/meteor-grey-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meteor Grey Boyfriend T-Shirt</td>\n",
       "      <td>₹ 349</td>\n",
       "      <td>399</td>\n",
       "      <td>https://images.bewakoof.com/t320/nimbus-grey-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minimal Believe Round Neck 3/4th Sleeve T-Shirt</td>\n",
       "      <td>₹ 249</td>\n",
       "      <td>499</td>\n",
       "      <td>https://images.bewakoof.com/t320/meteor-grey-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Women's Black Believe Slim Fit T-shirt</td>\n",
       "      <td>₹ 299</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Women's Black Believe Boyfriend T-shirt</td>\n",
       "      <td>₹ 399</td>\n",
       "      <td>549</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Nimbus Grey Round Neck 3/4th Sleeve T-Shirt</td>\n",
       "      <td>₹ 249</td>\n",
       "      <td>399</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Nimbus Grey Boyfriend T-Shirt</td>\n",
       "      <td>₹ 349</td>\n",
       "      <td>399</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Asche Bochor Round Neck 3/4th Sleeve T-Shirt N...</td>\n",
       "      <td>₹ 249</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name Discounted Price  \\\n",
       "0       Marshmello Mask Round Neck 3/4th Sleeve T-Shirt            ₹ 249   \n",
       "1     Women's Blue Escape The Ordinary Boyfriend T-s...            ₹ 399   \n",
       "2          Not Ordinary Round Neck 3/4th Sleeve T-Shirt            ₹ 249   \n",
       "3                         Meteor Grey Boyfriend T-Shirt            ₹ 349   \n",
       "4       Minimal Believe Round Neck 3/4th Sleeve T-Shirt            ₹ 249   \n",
       "...                                                 ...              ...   \n",
       "9995             Women's Black Believe Slim Fit T-shirt            ₹ 299   \n",
       "9996            Women's Black Believe Boyfriend T-shirt            ₹ 399   \n",
       "9997        Nimbus Grey Round Neck 3/4th Sleeve T-Shirt            ₹ 249   \n",
       "9998                      Nimbus Grey Boyfriend T-Shirt            ₹ 349   \n",
       "9999  Asche Bochor Round Neck 3/4th Sleeve T-Shirt N...            ₹ 249   \n",
       "\n",
       "     Actual Price                                                URL  \n",
       "0             499  https://images.bewakoof.com/t320/meteor-grey-b...  \n",
       "1             549  https://images.bewakoof.com/t320/nimbus-grey-b...  \n",
       "2             799  https://images.bewakoof.com/t320/meteor-grey-b...  \n",
       "3             399  https://images.bewakoof.com/t320/nimbus-grey-b...  \n",
       "4             499  https://images.bewakoof.com/t320/meteor-grey-b...  \n",
       "...           ...                                                ...  \n",
       "9995          499                                                NaN  \n",
       "9996          549                                                NaN  \n",
       "9997          399                                                NaN  \n",
       "9998          399                                                NaN  \n",
       "9999          499                                                NaN  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_listing = int(input('Enter the number of listings needed : '))\n",
    "\n",
    "from selenium import webdriver\n",
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "url = 'https://www.bewakoof.com/women-clothing'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "driver.get(url)\n",
    "\n",
    "page = driver.page_source\n",
    "soup = BeautifulSoup(page)\n",
    "bewakoof = []\n",
    "URL = []\n",
    "count = 0\n",
    "while  count != number_of_listing:\n",
    "    for main_file in soup.find_all('div',class_=\"productCardDetail\"):\n",
    "            name = main_file.find('h3').text\n",
    "            price = main_file.find('span',class_='discountedPriceText' ).text\n",
    "            org_price = main_file.find('span',attrs={'class':'actualPriceText'}).text\n",
    "            if (len(name))>0 or len(price)>0:\n",
    "                bewakoof.append([name,price,org_price])\n",
    "                count+=1\n",
    "    \n",
    "    for main_file in soup.find_all('div',class_=\"productImg\"):\n",
    "            url1 = main_file.find('img')['src']\n",
    "            URL.append(url1)\n",
    "            \n",
    "df1 = pd.DataFrame(URL)              \n",
    "df = pd.DataFrame(bewakoof,columns=['Name','Discounted Price','Actual Price'])\n",
    "df['URL']=df1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da26ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27c8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
